{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:07.683110Z",
     "start_time": "2024-03-02T22:28:02.504242Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import abc\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Utils(metaclass=abc.ABCMeta):\n",
    "    def __init__(self) -> None:\n",
    "        ()\n",
    "\n",
    "    def create_folder(self, folder_path: str) -> None:\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:11.924587Z",
     "start_time": "2024-03-02T22:28:11.914882Z"
    }
   },
   "id": "9e806f61df043328",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BagOfWordsClassifier():\n",
    "    def __init__(self):\n",
    "        self.counts = {}\n",
    "        self.counts_PCL = {}\n",
    "        self.counts_not_PCL = {}\n",
    "        self.PCL_word_count = 0\n",
    "        self.no_PCL_word_count = 0\n",
    "        self.PCL_document_count = 0\n",
    "        self.no_PCL_document_count = 0\n",
    "\n",
    "    def clean_text_tokenize(self, text):\n",
    "        stop_words = ['this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there',\n",
    "                      'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'don', \"don't\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'shan', \"shan't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "        text.lower()\n",
    "        # removing \" at start of sentences\n",
    "        text = text.strip(\"\\\"\")\n",
    "        # replacing repetitions of punctations\n",
    "        text = re.sub(r'\\\"+', '', text)\n",
    "\n",
    "        # Tokenize links\n",
    "        text = re.sub(r'https? : \\S+', '[WEBSITE]', text)\n",
    "        # removing referencing on usernames with @\n",
    "        text = re.sub(r'@\\S+', '', text)\n",
    "        # removing smileys with : (like :),:D,:( etc)\n",
    "        text = re.sub(r':\\S+', '', text)\n",
    "        # Remove punctation\n",
    "        text = re.sub(r\"[!.,;:?\\'\\\"\\´]\", \"\", text)\n",
    "        text = re.sub('(?<![\\w])20[0-5][0-9]-?[0-9]*',\n",
    "                    '[YEAR]', text)              # Year token\n",
    "        text = re.sub('(?<![\\w])1[0-9]{3}-?[0-9]*',\n",
    "                    '[YEAR]', text)                 # Year token\n",
    "        # replacing numbers with [NUM] tag  eg 1,000, 1.32, 5-7. Assert these numbers are not inside words (i.e. H1, )\n",
    "        text = re.sub('(?<![\\w])[0-9]+[.,]?[0-9]*(?![\\w])', '[NUM]', text)\n",
    "        text = re.sub('\\[NUM\\]-\\[NUM\\]', '[NUM]', text)\n",
    "        # Again to delete account numbers lol 12-5223-231\n",
    "        text = re.sub('\\[NUM\\]-\\[NUM\\]', '[NUM]', text)\n",
    "        text = re.sub('(?<=\\[NUM\\])-(?=[a-zA-Z])', ' ', text)\n",
    "        text = re.sub('[ ]*', ' ', text)\n",
    "        text = re.sub('<h>', '.', text)\n",
    "\n",
    "        porter = PorterStemmer()\n",
    "        words = text.split()\n",
    "        for i, word in enumerate(words):\n",
    "            if word in stop_words:\n",
    "                words.pop(i)\n",
    "            else:\n",
    "                words[i] = porter.stem(word)\n",
    "        return words\n",
    "\n",
    "    def train(self, train_DF):\n",
    "        for i, row in train_DF.iterrows():\n",
    "            text = row[\"text\"]\n",
    "            label = row[\"binary_label\"]\n",
    "\n",
    "            if label == 0:\n",
    "                self.no_PCL_document_count += 1\n",
    "            else:\n",
    "                self.PCL_document_count += 1\n",
    "\n",
    "            words = self.clean_text_tokenize(text)\n",
    "            for word in words:\n",
    "                self.counts[word] = 1 + \\\n",
    "                    (self.counts[word] if word in self.counts.keys() else 0)\n",
    "\n",
    "                if label == 0:\n",
    "                    self.no_PCL_word_count += 1\n",
    "                    self.counts_not_PCL[word] = 1 + \\\n",
    "                        (self.counts_not_PCL[word]\n",
    "                         if word in self.counts_not_PCL.keys() else 0)\n",
    "                else:\n",
    "                    self.PCL_word_count += 1\n",
    "                    self.counts_PCL[word] = 1 + \\\n",
    "                        (self.counts_PCL[word]\n",
    "                         if word in self.counts_PCL.keys() else 0)\n",
    "                    \n",
    "    def predict(self, sentences):\n",
    "\n",
    "        prior = self.PCL_document_count / \\\n",
    "            (self.PCL_document_count + self.no_PCL_document_count)\n",
    "        epsilon = 1  # epsilon smoothing\n",
    "        if type(sentences) is str:\n",
    "            sentences = [sentences]\n",
    "        if type(sentences) is pd.DataFrame:\n",
    "            i, sentences = sentences.iterrows()\n",
    "\n",
    "        predictions = []\n",
    "        for sentence in sentences:\n",
    "\n",
    "            likelihood = 1\n",
    "            for word in sentence:\n",
    "                class_count = self.counts_PCL[word] if word in self.counts_PCL.keys(\n",
    "                ) else 0\n",
    "                likelihood *= (class_count+epsilon) / \\\n",
    "                    (len(self.counts) + self.PCL_word_count)\n",
    "\n",
    "            prob_PCL = prior*likelihood\n",
    "\n",
    "            likelihood = 1\n",
    "            for word in sentence:\n",
    "                class_count = self.counts_not_PCL[word] if word in self.counts_not_PCL.keys(\n",
    "                ) else 0\n",
    "                likelihood *= (class_count+epsilon) / \\\n",
    "                    (len(self.counts) + self.no_PCL_word_count)\n",
    "\n",
    "            prob_not_PCL = (1-prior)*likelihood\n",
    "\n",
    "            predictions.append(1 if prob_PCL > prob_not_PCL else 0)\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:12.668847Z",
     "start_time": "2024-03-02T22:28:12.641669Z"
    }
   },
   "id": "5b1dd3a59eca3337",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('./data/dontpatronizeme_pcl.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "train_id = pd.read_csv(\"./data/train_semeval_parids-labels.csv\")\n",
    "dev_id = pd.read_csv(\"./data/dev_semeval_parids-labels.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:14.020793Z",
     "start_time": "2024-03-02T22:28:13.706528Z"
    }
   },
   "id": "c8d82693a8d66a74",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       par_id    art_id     keyword country_code  \\\n0           1  24942188    hopeless           ph   \n1           2  21968160     migrant           gh   \n2           3  16584954   immigrant           ie   \n3           4   7811231    disabled           nz   \n4           5   1494111     refugee           ca   \n...       ...       ...         ...          ...   \n10407   10408   4542224    homeless           my   \n10423   10424   4665292       women           jm   \n10444   10445   3923193     refugee           gb   \n10453   10454  22338535  vulnerable           ie   \n10466   10467  20282330     in-need           ng   \n\n                                                    text  label  binary_label  \n0      We 're living in times of absolute insanity , ...    0.0           0.0  \n1      In Libya today , there are countless number of...    0.0           0.0  \n2      \"White House press secretary Sean Spicer said ...    0.0           0.0  \n3      Council customers only signs would be displaye...    0.0           0.0  \n4      \"\"\" Just like we received migrants fleeing El ...    0.0           0.0  \n...                                                  ...    ...           ...  \n10407  \"\"\" Most of them ( the homeless ) have the abi...    3.0           1.0  \n10423  \"\"\" I do n't believe in abortion , I think it ...    3.0           1.0  \n10444  More than 150 volunteers spent the night in ' ...    3.0           1.0  \n10453  \"\"\" We are challenged , I suggest , to turn th...    4.0           1.0  \n10466  \"\"\" She has one huge platform , and informatio...    3.0           1.0  \n\n[8374 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>par_id</th>\n      <th>art_id</th>\n      <th>keyword</th>\n      <th>country_code</th>\n      <th>text</th>\n      <th>label</th>\n      <th>binary_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24942188</td>\n      <td>hopeless</td>\n      <td>ph</td>\n      <td>We 're living in times of absolute insanity , ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>21968160</td>\n      <td>migrant</td>\n      <td>gh</td>\n      <td>In Libya today , there are countless number of...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>16584954</td>\n      <td>immigrant</td>\n      <td>ie</td>\n      <td>\"White House press secretary Sean Spicer said ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>7811231</td>\n      <td>disabled</td>\n      <td>nz</td>\n      <td>Council customers only signs would be displaye...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1494111</td>\n      <td>refugee</td>\n      <td>ca</td>\n      <td>\"\"\" Just like we received migrants fleeing El ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10407</th>\n      <td>10408</td>\n      <td>4542224</td>\n      <td>homeless</td>\n      <td>my</td>\n      <td>\"\"\" Most of them ( the homeless ) have the abi...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10423</th>\n      <td>10424</td>\n      <td>4665292</td>\n      <td>women</td>\n      <td>jm</td>\n      <td>\"\"\" I do n't believe in abortion , I think it ...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10444</th>\n      <td>10445</td>\n      <td>3923193</td>\n      <td>refugee</td>\n      <td>gb</td>\n      <td>More than 150 volunteers spent the night in ' ...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10453</th>\n      <td>10454</td>\n      <td>22338535</td>\n      <td>vulnerable</td>\n      <td>ie</td>\n      <td>\"\"\" We are challenged , I suggest , to turn th...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10466</th>\n      <td>10467</td>\n      <td>20282330</td>\n      <td>in-need</td>\n      <td>ng</td>\n      <td>\"\"\" She has one huge platform , and informatio...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8374 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pcl_train = df[df[\"par_id\"].isin(train_id[\"par_id\"].tolist())]\n",
    "data_pcl_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:14.702721Z",
     "start_time": "2024-03-02T22:28:14.685847Z"
    }
   },
   "id": "dbe29125aacc8688",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = \"./data/GoogleNews-vectors-negative300.bin.gz\"\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:51.523299Z",
     "start_time": "2024-03-02T22:28:15.714432Z"
    }
   },
   "id": "6ef82f5dd61873c8",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def word_emedding_average(text):\n",
    "    words = text.split()\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        if word in model.key_to_index:\n",
    "            vector = model[word]\n",
    "            embeddings.append(vector)\n",
    "    return np.mean(np.array(embeddings), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:51.537614Z",
     "start_time": "2024-03-02T22:28:51.525363Z"
    }
   },
   "id": "26336db9c037bcca",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#建了一个新的列 length_text，其内容是 data_pcl_train 中每个 text 列中文本的长度\n",
    "data_pcl_train[\"length_text\"] = data_pcl_train[\"text\"].apply(lambda x: len(x))\n",
    "\n",
    "# 创建了一个新的列 word_embedding，通过应用 word_emedding_average 函数于 text 列的每个元素上。\n",
    "# 这个函数的作用是将每个文本转换为一个词嵌入向量（word embedding），通常是通过计算文本中所有词向量的平均值来获得\n",
    "data_pcl_train[\"word_embedding\"] = data_pcl_train[\"text\"].apply(lambda x: word_emedding_average(x))\n",
    "\n",
    "# # 将 word_embedding 列中的每个嵌入向量展开成 300 个独立的列（假设每个词嵌入向量的维度为 300\n",
    "data_pcl_train[[i for i in range(300)]] = data_pcl_train['word_embedding'].apply(lambda x: pd.Series(x))\n",
    "\n",
    "# 移除了 data_pcl_train 中不再需要的列，包括原始的 word_embedding 列（因为其内容已经被展开到新的列中了），以及 par_id、art_id、text 和 label 这几列\n",
    "data_pcl_train.drop(['word_embedding','par_id','art_id','text','label'], axis=1, inplace=True)\n",
    "\n",
    "# 将 country_code 和 keyword 列中的文本类别转换为数值代码\n",
    "data_pcl_train[\"country_code\"] = pd.Categorical(data_pcl_train[\"country_code\"], categories=data_pcl_train[\"country_code\"].unique()).codes\n",
    "data_pcl_train[\"keyword\"] = pd.Categorical(data_pcl_train[\"keyword\"], categories=data_pcl_train[\"keyword\"].unique()).codes\n",
    "\n",
    "data_pcl_train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e798a4910cc9449",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Y_train = data_pcl_train[\"binary_label\"].astype(\"float\").to_numpy()\n",
    "X_train = data_pcl_train.drop(['binary_label'], axis=1, inplace=False).astype(\"float\").to_numpy()\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=0).fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "183ce28510848381",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('standardscaler', StandardScaler()),\n                ('svc', SVC(random_state=42))])",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n                (&#x27;svc&#x27;, SVC(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n                (&#x27;svc&#x27;, SVC(random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(random_state=42)</pre></div> </div></div></div></div></div></div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# 分离特征和标签\n",
    "Y_train = data_pcl_train[\"binary_label\"].astype(\"float\").to_numpy()\n",
    "X_train = data_pcl_train.drop(['binary_label'], axis=1, inplace=False).astype(\"float\").to_numpy()\n",
    "\n",
    "svm_pipeline = make_pipeline(StandardScaler(), SVC(random_state=42))\n",
    "svm_pipeline.fit(X_train, Y_train)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:57.109080Z",
     "start_time": "2024-03-02T22:28:54.120658Z"
    }
   },
   "id": "ceef44042289315",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def word_embedding_average_modified(text):\n",
    "    if isinstance(text, str):\n",
    "        # 如果 text 是字符串，执行原来的逻辑\n",
    "        return word_emedding_average(text)\n",
    "        print(aaaa)\n",
    "    else:\n",
    "        # 如果 text 不是字符串（比如 NaN），返回一个全零的向量\n",
    "        return [0] * 300  # 假设词嵌入向量的维度为 300"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:57.116965Z",
     "start_time": "2024-03-02T22:28:57.110504Z"
    }
   },
   "id": "49617b443b08dc8e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_pcl_dev = df[df[\"par_id\"].isin(dev_id[\"par_id\"].tolist())]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:57.119121Z",
     "start_time": "2024-03-02T22:28:57.115124Z"
    }
   },
   "id": "30ea6d6a9fb1b87d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       par_id    art_id        keyword country_code  \\\n106       107  16900972       homeless           ke   \n148       149   1387882       disabled           us   \n150       151  19974860  poor-families           in   \n153       154  20663936       disabled           ng   \n156       157  21712008  poor-families           ca   \n...       ...       ...            ...          ...   \n10462   10463   4676355        refugee           pk   \n10463   10464  19612634       disabled           ie   \n10464   10465  14297363          women           lk   \n10465   10466  70091353     vulnerable           ph   \n10467   10468  16753236       hopeless           in   \n\n                                                    text  label  binary_label  \n106    \"His present \"\" chambers \"\" may be quite humbl...    3.0           1.0  \n148    Krueger recently harnessed that creativity to ...    2.0           1.0  \n150    10:41am - Parents of children who died must ge...    3.0           1.0  \n153    When some people feel causing problem for some...    4.0           1.0  \n156    We are alarmed to learn of your recently circu...    4.0           1.0  \n...                                                  ...    ...           ...  \n10462  \"\"\" The Pakistani police came to our house and...    0.0           0.0  \n10463  \"When Marie O'Donoghue went looking for a spec...    0.0           0.0  \n10464  \"Sri Lankan norms and culture inhibit women fr...    1.0           0.0  \n10465  He added that the AFP will continue to bank on...    0.0           0.0  \n10467  \"\"\" Anja Ringgren Loven I ca n't find a word t...    4.0           1.0  \n\n[2093 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>par_id</th>\n      <th>art_id</th>\n      <th>keyword</th>\n      <th>country_code</th>\n      <th>text</th>\n      <th>label</th>\n      <th>binary_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106</th>\n      <td>107</td>\n      <td>16900972</td>\n      <td>homeless</td>\n      <td>ke</td>\n      <td>\"His present \"\" chambers \"\" may be quite humbl...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>149</td>\n      <td>1387882</td>\n      <td>disabled</td>\n      <td>us</td>\n      <td>Krueger recently harnessed that creativity to ...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>151</td>\n      <td>19974860</td>\n      <td>poor-families</td>\n      <td>in</td>\n      <td>10:41am - Parents of children who died must ge...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>154</td>\n      <td>20663936</td>\n      <td>disabled</td>\n      <td>ng</td>\n      <td>When some people feel causing problem for some...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>157</td>\n      <td>21712008</td>\n      <td>poor-families</td>\n      <td>ca</td>\n      <td>We are alarmed to learn of your recently circu...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10462</th>\n      <td>10463</td>\n      <td>4676355</td>\n      <td>refugee</td>\n      <td>pk</td>\n      <td>\"\"\" The Pakistani police came to our house and...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10463</th>\n      <td>10464</td>\n      <td>19612634</td>\n      <td>disabled</td>\n      <td>ie</td>\n      <td>\"When Marie O'Donoghue went looking for a spec...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10464</th>\n      <td>10465</td>\n      <td>14297363</td>\n      <td>women</td>\n      <td>lk</td>\n      <td>\"Sri Lankan norms and culture inhibit women fr...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10465</th>\n      <td>10466</td>\n      <td>70091353</td>\n      <td>vulnerable</td>\n      <td>ph</td>\n      <td>He added that the AFP will continue to bank on...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10467</th>\n      <td>10468</td>\n      <td>16753236</td>\n      <td>hopeless</td>\n      <td>in</td>\n      <td>\"\"\" Anja Ringgren Loven I ca n't find a word t...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2093 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pcl_dev"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:57.130168Z",
     "start_time": "2024-03-02T22:28:57.124167Z"
    }
   },
   "id": "38116e642a93489b",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 为 data_pcl_dev 中的每个文本条目计算字符长度，并将这些长度值存储在新的列 length_text 中\n",
    "# data_pcl_dev[\"length_text\"] = data_pcl_dev[\"text\"].apply(lambda x: len(x))\n",
    "data_pcl_dev[\"length_text\"] = data_pcl_dev[\"text\"].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "# ，对每个文本条目应用 word_emedding_average 函数，生成一个词嵌入向量，并将这些向量存储在新的列 word_embedding 中\n",
    "data_pcl_dev[\"word_embedding\"] = data_pcl_dev[\"text\"].apply(lambda x: word_embedding_average_modified(x))\n",
    "\n",
    "# 将 word_embedding 列中的向量展开到 300 个独立的列中（假设每个词嵌入向量的维度为 300）\n",
    "data_pcl_dev[[i for i in range(300)]] = data_pcl_dev['word_embedding'].apply(lambda x: pd.Series(x))\n",
    "\n",
    "#  删除了 word_embedding（因为它的内容已经被展开到新的列中了）、par_id、art_id、text 和 label 这些列\n",
    "data_pcl_dev.drop(['word_embedding','par_id','art_id','text','label'], axis=1, inplace=True)\n",
    "data_pcl_dev[\"country_code\"] = pd.Categorical(data_pcl_dev[\"country_code\"], categories=data_pcl_dev[\"country_code\"].unique()).codes\n",
    "data_pcl_dev[\"keyword\"] = pd.Categorical(data_pcl_dev[\"keyword\"], categories=data_pcl_dev[\"keyword\"].unique()).codes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7422a09465cf981e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       keyword  country_code  binary_label  length_text         0         1  \\\n106          0             0           1.0          400  0.040616  0.053745   \n148          1             1           1.0          296  0.029581  0.035252   \n150          2             2           1.0          138  0.031295  0.028444   \n153          1             3           1.0          496  0.063602  0.054059   \n156          2             4           1.0          601  0.030542  0.035941   \n...        ...           ...           ...          ...       ...       ...   \n10462        5            13           0.0          172  0.025852  0.102847   \n10463        1             7           0.0          203  0.074717  0.018960   \n10464        4             6           0.0          348  0.021482  0.087925   \n10465        9            10           0.0          258 -0.007844  0.078821   \n10467        7             2           1.0          502  0.075467  0.024462   \n\n              2         3         4         5  ...       290       291  \\\n106    0.023178  0.041561 -0.088367 -0.019397  ... -0.099189  0.011189   \n148    0.010618  0.084094 -0.045408  0.003664  ... -0.077357 -0.016581   \n150    0.036345  0.156867 -0.032007 -0.030412  ... -0.099141  0.000726   \n153    0.019293  0.100153 -0.101033  0.012160  ... -0.052560  0.050858   \n156   -0.033920  0.073037 -0.067282 -0.003469  ... -0.042028 -0.015475   \n...         ...       ...       ...       ...  ...       ...       ...   \n10462  0.078958  0.054771 -0.060840 -0.038958  ... -0.067443  0.030520   \n10463  0.059744  0.018926 -0.030449 -0.047268  ... -0.085388 -0.052651   \n10464  0.024637  0.040627 -0.003054  0.010264  ... -0.093884  0.024587   \n10465  0.024941  0.076679 -0.073365 -0.037882  ... -0.113297  0.021043   \n10467  0.004272  0.135012 -0.038653  0.022275  ... -0.040688  0.082510   \n\n            292       293       294       295       296       297       298  \\\n106   -0.091196  0.033318 -0.042895  0.023637  0.004139 -0.033890  0.042187   \n148   -0.119857 -0.035556 -0.050116  0.014409  0.041216 -0.043842  0.042561   \n150   -0.069391  0.007742  0.045618  0.049137 -0.117510 -0.025179  0.081567   \n153   -0.094168 -0.001755 -0.024271  0.010481 -0.011790 -0.051126  0.047470   \n156   -0.095195  0.016387 -0.021685 -0.000462 -0.002560 -0.008348  0.067242   \n...         ...       ...       ...       ...       ...       ...       ...   \n10462 -0.068782  0.016903 -0.085384  0.060193  0.024922 -0.011949  0.086685   \n10463 -0.112657  0.062949 -0.039978  0.004479  0.005023 -0.034573  0.063049   \n10464 -0.097566 -0.041327 -0.041133  0.005601  0.064697 -0.023188  0.043588   \n10465 -0.074065  0.000114 -0.050973  0.071761  0.008267 -0.050337  0.029896   \n10467 -0.132347 -0.032920 -0.038491 -0.041258  0.001752 -0.068345  0.006509   \n\n            299  \n106   -0.028945  \n148   -0.068234  \n150    0.045866  \n153   -0.020584  \n156   -0.031580  \n...         ...  \n10462 -0.015989  \n10463  0.005879  \n10464 -0.010489  \n10465 -0.039081  \n10467 -0.029607  \n\n[2093 rows x 304 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>country_code</th>\n      <th>binary_label</th>\n      <th>length_text</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>400</td>\n      <td>0.040616</td>\n      <td>0.053745</td>\n      <td>0.023178</td>\n      <td>0.041561</td>\n      <td>-0.088367</td>\n      <td>-0.019397</td>\n      <td>...</td>\n      <td>-0.099189</td>\n      <td>0.011189</td>\n      <td>-0.091196</td>\n      <td>0.033318</td>\n      <td>-0.042895</td>\n      <td>0.023637</td>\n      <td>0.004139</td>\n      <td>-0.033890</td>\n      <td>0.042187</td>\n      <td>-0.028945</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>296</td>\n      <td>0.029581</td>\n      <td>0.035252</td>\n      <td>0.010618</td>\n      <td>0.084094</td>\n      <td>-0.045408</td>\n      <td>0.003664</td>\n      <td>...</td>\n      <td>-0.077357</td>\n      <td>-0.016581</td>\n      <td>-0.119857</td>\n      <td>-0.035556</td>\n      <td>-0.050116</td>\n      <td>0.014409</td>\n      <td>0.041216</td>\n      <td>-0.043842</td>\n      <td>0.042561</td>\n      <td>-0.068234</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>138</td>\n      <td>0.031295</td>\n      <td>0.028444</td>\n      <td>0.036345</td>\n      <td>0.156867</td>\n      <td>-0.032007</td>\n      <td>-0.030412</td>\n      <td>...</td>\n      <td>-0.099141</td>\n      <td>0.000726</td>\n      <td>-0.069391</td>\n      <td>0.007742</td>\n      <td>0.045618</td>\n      <td>0.049137</td>\n      <td>-0.117510</td>\n      <td>-0.025179</td>\n      <td>0.081567</td>\n      <td>0.045866</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>496</td>\n      <td>0.063602</td>\n      <td>0.054059</td>\n      <td>0.019293</td>\n      <td>0.100153</td>\n      <td>-0.101033</td>\n      <td>0.012160</td>\n      <td>...</td>\n      <td>-0.052560</td>\n      <td>0.050858</td>\n      <td>-0.094168</td>\n      <td>-0.001755</td>\n      <td>-0.024271</td>\n      <td>0.010481</td>\n      <td>-0.011790</td>\n      <td>-0.051126</td>\n      <td>0.047470</td>\n      <td>-0.020584</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>2</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>601</td>\n      <td>0.030542</td>\n      <td>0.035941</td>\n      <td>-0.033920</td>\n      <td>0.073037</td>\n      <td>-0.067282</td>\n      <td>-0.003469</td>\n      <td>...</td>\n      <td>-0.042028</td>\n      <td>-0.015475</td>\n      <td>-0.095195</td>\n      <td>0.016387</td>\n      <td>-0.021685</td>\n      <td>-0.000462</td>\n      <td>-0.002560</td>\n      <td>-0.008348</td>\n      <td>0.067242</td>\n      <td>-0.031580</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10462</th>\n      <td>5</td>\n      <td>13</td>\n      <td>0.0</td>\n      <td>172</td>\n      <td>0.025852</td>\n      <td>0.102847</td>\n      <td>0.078958</td>\n      <td>0.054771</td>\n      <td>-0.060840</td>\n      <td>-0.038958</td>\n      <td>...</td>\n      <td>-0.067443</td>\n      <td>0.030520</td>\n      <td>-0.068782</td>\n      <td>0.016903</td>\n      <td>-0.085384</td>\n      <td>0.060193</td>\n      <td>0.024922</td>\n      <td>-0.011949</td>\n      <td>0.086685</td>\n      <td>-0.015989</td>\n    </tr>\n    <tr>\n      <th>10463</th>\n      <td>1</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>203</td>\n      <td>0.074717</td>\n      <td>0.018960</td>\n      <td>0.059744</td>\n      <td>0.018926</td>\n      <td>-0.030449</td>\n      <td>-0.047268</td>\n      <td>...</td>\n      <td>-0.085388</td>\n      <td>-0.052651</td>\n      <td>-0.112657</td>\n      <td>0.062949</td>\n      <td>-0.039978</td>\n      <td>0.004479</td>\n      <td>0.005023</td>\n      <td>-0.034573</td>\n      <td>0.063049</td>\n      <td>0.005879</td>\n    </tr>\n    <tr>\n      <th>10464</th>\n      <td>4</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>348</td>\n      <td>0.021482</td>\n      <td>0.087925</td>\n      <td>0.024637</td>\n      <td>0.040627</td>\n      <td>-0.003054</td>\n      <td>0.010264</td>\n      <td>...</td>\n      <td>-0.093884</td>\n      <td>0.024587</td>\n      <td>-0.097566</td>\n      <td>-0.041327</td>\n      <td>-0.041133</td>\n      <td>0.005601</td>\n      <td>0.064697</td>\n      <td>-0.023188</td>\n      <td>0.043588</td>\n      <td>-0.010489</td>\n    </tr>\n    <tr>\n      <th>10465</th>\n      <td>9</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>258</td>\n      <td>-0.007844</td>\n      <td>0.078821</td>\n      <td>0.024941</td>\n      <td>0.076679</td>\n      <td>-0.073365</td>\n      <td>-0.037882</td>\n      <td>...</td>\n      <td>-0.113297</td>\n      <td>0.021043</td>\n      <td>-0.074065</td>\n      <td>0.000114</td>\n      <td>-0.050973</td>\n      <td>0.071761</td>\n      <td>0.008267</td>\n      <td>-0.050337</td>\n      <td>0.029896</td>\n      <td>-0.039081</td>\n    </tr>\n    <tr>\n      <th>10467</th>\n      <td>7</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>502</td>\n      <td>0.075467</td>\n      <td>0.024462</td>\n      <td>0.004272</td>\n      <td>0.135012</td>\n      <td>-0.038653</td>\n      <td>0.022275</td>\n      <td>...</td>\n      <td>-0.040688</td>\n      <td>0.082510</td>\n      <td>-0.132347</td>\n      <td>-0.032920</td>\n      <td>-0.038491</td>\n      <td>-0.041258</td>\n      <td>0.001752</td>\n      <td>-0.068345</td>\n      <td>0.006509</td>\n      <td>-0.029607</td>\n    </tr>\n  </tbody>\n</table>\n<p>2093 rows × 304 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pcl_dev"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:28:57.542261Z",
     "start_time": "2024-03-02T22:28:57.530988Z"
    }
   },
   "id": "c5477371d2f778d5",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on train:0.6873309626619253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = svm_pipeline.predict(X_train)\n",
    "print(f\"F1-score on train:{f1_score(Y_train, y_pred, average='macro')}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:29:02.118534Z",
     "start_time": "2024-03-02T22:28:57.545898Z"
    }
   },
   "id": "b2d525345060ce6f",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on dev:0.5411372329508349\n"
     ]
    }
   ],
   "source": [
    "Y_test = data_pcl_dev[\"binary_label\"].astype(\"float\").to_numpy()\n",
    "X_test = data_pcl_dev.drop(['binary_label'], axis=1, inplace=False).astype(\"float\").to_numpy()\n",
    "\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "print(f\"F1-score on dev:{f1_score(Y_test, y_pred, average='macro')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:29:03.238470Z",
     "start_time": "2024-03-02T22:29:02.118980Z"
    }
   },
   "id": "51420bffa3cdbd5d",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import re \n",
    "\n",
    "df = pd.read_csv(\"./data/dontpatronizeme_pcl.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "train_id = pd.read_csv(\"./data/train_semeval_parids-labels.csv\")\n",
    "dev_id = pd.read_csv(\"./data/dev_semeval_parids-labels.csv\")\n",
    "\n",
    "data_pcl_train = df[df[\"par_id\"].isin(train_id[\"par_id\"].tolist())]\n",
    "data_pcl_dev = df[df[\"par_id\"].isin(dev_id[\"par_id\"].tolist())]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:29:04.013326Z",
     "start_time": "2024-03-02T22:29:03.235939Z"
    }
   },
   "id": "e1af89c8ff9f55ee",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10467, 7)\n",
      "(8375, 2)\n",
      "(2094, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(train_id.shape)\n",
    "print(dev_id.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:29:04.023853Z",
     "start_time": "2024-03-02T22:29:04.015822Z"
    }
   },
   "id": "9ee8b7f1caf6fbbe",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       par_id    art_id        keyword country_code  \\\n106       107  16900972       homeless           ke   \n148       149   1387882       disabled           us   \n150       151  19974860  poor-families           in   \n153       154  20663936       disabled           ng   \n156       157  21712008  poor-families           ca   \n...       ...       ...            ...          ...   \n10462   10463   4676355        refugee           pk   \n10463   10464  19612634       disabled           ie   \n10464   10465  14297363          women           lk   \n10465   10466  70091353     vulnerable           ph   \n10467   10468  16753236       hopeless           in   \n\n                                                    text  label  binary_label  \n106    \"His present \"\" chambers \"\" may be quite humbl...    3.0           1.0  \n148    Krueger recently harnessed that creativity to ...    2.0           1.0  \n150    10:41am - Parents of children who died must ge...    3.0           1.0  \n153    When some people feel causing problem for some...    4.0           1.0  \n156    We are alarmed to learn of your recently circu...    4.0           1.0  \n...                                                  ...    ...           ...  \n10462  \"\"\" The Pakistani police came to our house and...    0.0           0.0  \n10463  \"When Marie O'Donoghue went looking for a spec...    0.0           0.0  \n10464  \"Sri Lankan norms and culture inhibit women fr...    1.0           0.0  \n10465  He added that the AFP will continue to bank on...    0.0           0.0  \n10467  \"\"\" Anja Ringgren Loven I ca n't find a word t...    4.0           1.0  \n\n[2093 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>par_id</th>\n      <th>art_id</th>\n      <th>keyword</th>\n      <th>country_code</th>\n      <th>text</th>\n      <th>label</th>\n      <th>binary_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106</th>\n      <td>107</td>\n      <td>16900972</td>\n      <td>homeless</td>\n      <td>ke</td>\n      <td>\"His present \"\" chambers \"\" may be quite humbl...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>149</td>\n      <td>1387882</td>\n      <td>disabled</td>\n      <td>us</td>\n      <td>Krueger recently harnessed that creativity to ...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>151</td>\n      <td>19974860</td>\n      <td>poor-families</td>\n      <td>in</td>\n      <td>10:41am - Parents of children who died must ge...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>154</td>\n      <td>20663936</td>\n      <td>disabled</td>\n      <td>ng</td>\n      <td>When some people feel causing problem for some...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>157</td>\n      <td>21712008</td>\n      <td>poor-families</td>\n      <td>ca</td>\n      <td>We are alarmed to learn of your recently circu...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10462</th>\n      <td>10463</td>\n      <td>4676355</td>\n      <td>refugee</td>\n      <td>pk</td>\n      <td>\"\"\" The Pakistani police came to our house and...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10463</th>\n      <td>10464</td>\n      <td>19612634</td>\n      <td>disabled</td>\n      <td>ie</td>\n      <td>\"When Marie O'Donoghue went looking for a spec...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10464</th>\n      <td>10465</td>\n      <td>14297363</td>\n      <td>women</td>\n      <td>lk</td>\n      <td>\"Sri Lankan norms and culture inhibit women fr...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10465</th>\n      <td>10466</td>\n      <td>70091353</td>\n      <td>vulnerable</td>\n      <td>ph</td>\n      <td>He added that the AFP will continue to bank on...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10467</th>\n      <td>10468</td>\n      <td>16753236</td>\n      <td>hopeless</td>\n      <td>in</td>\n      <td>\"\"\" Anja Ringgren Loven I ca n't find a word t...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2093 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pcl_dev"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:29:04.034364Z",
     "start_time": "2024-03-02T22:29:04.030263Z"
    }
   },
   "id": "3ab414b4938a46c",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classifier_bow = BagOfWordsClassifier()\n",
    "classifier_bow.train(data_pcl_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:29:07.413067Z",
     "start_time": "2024-03-02T22:29:04.053577Z"
    }
   },
   "id": "17e71e9b0d3e5f9a",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on train: 0.4864682403042344\n",
      "Misclassified samples:\n",
      "       par_id    art_id     keyword country_code  \\\n",
      "8           9   3449225    homeless           ph   \n",
      "12         13  13499386       women           pk   \n",
      "16         17   8886184    hopeless           sg   \n",
      "22         23  25154641    homeless           ca   \n",
      "25         26   3659219       women           za   \n",
      "...       ...       ...         ...          ...   \n",
      "10406   10407   1811952     in-need           tz   \n",
      "10407   10408   4542224    homeless           my   \n",
      "10423   10424   4665292       women           jm   \n",
      "10453   10454  22338535  vulnerable           ie   \n",
      "10466   10467  20282330     in-need           ng   \n",
      "\n",
      "                                                    text  label  binary_label  \\\n",
      "8      NUEVA ERA , Ilocos Norte - No family shall be ...    1.0           0.0   \n",
      "12     \"\"\" Ghostbusters \"\" is a resurrection of the 1...    0.0           0.0   \n",
      "16     For those few seconds , humanity is free of it...    0.0           0.0   \n",
      "22     \"\"\" It highlights that different communities r...    0.0           0.0   \n",
      "25     Some say that a review of the legislation of s...    0.0           0.0   \n",
      "...                                                  ...    ...           ...   \n",
      "10406  \"He said his decision to help those in need di...    3.0           1.0   \n",
      "10407  \"\"\" Most of them ( the homeless ) have the abi...    3.0           1.0   \n",
      "10423  \"\"\" I do n't believe in abortion , I think it ...    3.0           1.0   \n",
      "10453  \"\"\" We are challenged , I suggest , to turn th...    4.0           1.0   \n",
      "10466  \"\"\" She has one huge platform , and informatio...    3.0           1.0   \n",
      "\n",
      "       predicted_label  \n",
      "8                    1  \n",
      "12                   1  \n",
      "16                   1  \n",
      "22                   1  \n",
      "25                   1  \n",
      "...                ...  \n",
      "10406                0  \n",
      "10407                0  \n",
      "10423                0  \n",
      "10453                0  \n",
      "10466                0  \n",
      "\n",
      "[2049 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/qkvpg3_11nz85hnd4k7_jgm00000gn/T/ipykernel_26553/2975618301.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pcl_train['predicted_label'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = classifier_bow.predict(data_pcl_train['text'])\n",
    "print(f\"F1-score on train: {f1_score(data_pcl_train['binary_label'], y_pred, average='macro')}\")\n",
    "\n",
    "data_pcl_train['predicted_label'] = y_pred\n",
    "misclassified = data_pcl_train[data_pcl_train['binary_label'] != data_pcl_train['predicted_label']]\n",
    "\n",
    "# 显示分类错误的数据\n",
    "print(\"Misclassified samples:\")\n",
    "print(misclassified)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T23:11:28.006463Z",
     "start_time": "2024-03-02T23:11:25.298600Z"
    }
   },
   "id": "656087175ee1d833",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       par_id    art_id     keyword country_code  \\\n0           1  24942188    hopeless           ph   \n1           2  21968160     migrant           gh   \n2           3  16584954   immigrant           ie   \n3           4   7811231    disabled           nz   \n4           5   1494111     refugee           ca   \n...       ...       ...         ...          ...   \n10407   10408   4542224    homeless           my   \n10423   10424   4665292       women           jm   \n10444   10445   3923193     refugee           gb   \n10453   10454  22338535  vulnerable           ie   \n10466   10467  20282330     in-need           ng   \n\n                                                    text  label  binary_label  \\\n0      We 're living in times of absolute insanity , ...    0.0           0.0   \n1      In Libya today , there are countless number of...    0.0           0.0   \n2      \"White House press secretary Sean Spicer said ...    0.0           0.0   \n3      Council customers only signs would be displaye...    0.0           0.0   \n4      \"\"\" Just like we received migrants fleeing El ...    0.0           0.0   \n...                                                  ...    ...           ...   \n10407  \"\"\" Most of them ( the homeless ) have the abi...    3.0           1.0   \n10423  \"\"\" I do n't believe in abortion , I think it ...    3.0           1.0   \n10444  More than 150 volunteers spent the night in ' ...    3.0           1.0   \n10453  \"\"\" We are challenged , I suggest , to turn th...    4.0           1.0   \n10466  \"\"\" She has one huge platform , and informatio...    3.0           1.0   \n\n       predicted_label  \n0                    0  \n1                    0  \n2                    0  \n3                    0  \n4                    0  \n...                ...  \n10407                0  \n10423                0  \n10444                1  \n10453                0  \n10466                0  \n\n[8374 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>par_id</th>\n      <th>art_id</th>\n      <th>keyword</th>\n      <th>country_code</th>\n      <th>text</th>\n      <th>label</th>\n      <th>binary_label</th>\n      <th>predicted_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24942188</td>\n      <td>hopeless</td>\n      <td>ph</td>\n      <td>We 're living in times of absolute insanity , ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>21968160</td>\n      <td>migrant</td>\n      <td>gh</td>\n      <td>In Libya today , there are countless number of...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>16584954</td>\n      <td>immigrant</td>\n      <td>ie</td>\n      <td>\"White House press secretary Sean Spicer said ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>7811231</td>\n      <td>disabled</td>\n      <td>nz</td>\n      <td>Council customers only signs would be displaye...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1494111</td>\n      <td>refugee</td>\n      <td>ca</td>\n      <td>\"\"\" Just like we received migrants fleeing El ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10407</th>\n      <td>10408</td>\n      <td>4542224</td>\n      <td>homeless</td>\n      <td>my</td>\n      <td>\"\"\" Most of them ( the homeless ) have the abi...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10423</th>\n      <td>10424</td>\n      <td>4665292</td>\n      <td>women</td>\n      <td>jm</td>\n      <td>\"\"\" I do n't believe in abortion , I think it ...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10444</th>\n      <td>10445</td>\n      <td>3923193</td>\n      <td>refugee</td>\n      <td>gb</td>\n      <td>More than 150 volunteers spent the night in ' ...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10453</th>\n      <td>10454</td>\n      <td>22338535</td>\n      <td>vulnerable</td>\n      <td>ie</td>\n      <td>\"\"\" We are challenged , I suggest , to turn th...</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10466</th>\n      <td>10467</td>\n      <td>20282330</td>\n      <td>in-need</td>\n      <td>ng</td>\n      <td>\"\"\" She has one huge platform , and informatio...</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8374 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pcl_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T23:11:41.838872Z",
     "start_time": "2024-03-02T23:11:41.811425Z"
    }
   },
   "id": "180816bde8ccc086",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2093\n",
      "F1-score on dev:0.4710545826540191\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier_bow.predict(data_pcl_dev['text'])\n",
    "print(len(y_pred))\n",
    "print(f\"F1-score on dev:{f1_score(Y_test, y_pred, average='macro')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T22:32:11.441073Z",
     "start_time": "2024-03-02T22:32:10.922149Z"
    }
   },
   "id": "64177c01ea28ca8c",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a75377a681a8f208"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "82a7fc43e2c583f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
