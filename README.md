# Natural Language Processing for predicting Patronizing and Condescending Language (PCL)

## Contributors

- Angelos Ragkousis
- Kyveli Tsioli
- Mengyu Rao

## Summary

- Implemented data augmentation through back-translation (English and French) on the "Don't Patronize Me!" dataset.
- Developed a custom BERT-based model that improved the F1 score for predicting Patronizing and Condescending Language (PCL) from 0.48 to 0.55, outperforming the baseline RoBERTa model.
- Performed model fine-tuning, experimenting with single vs. multi-layer projection heads and varying dropout rates.

Full report: https://1drv.ms/b/s!AqExWWOvFUogg5w3Jz4OE7zdZgq8rA?e=WcU3cM 

Skills: Hugging Face, Git, Pandas, NumPy
